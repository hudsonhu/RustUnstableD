{
 "cells": [
 {
  "cell_type": "markdown",
  "metadata": {},
  "source": [
    "# Rust Unstable Feature Analysis (v3)\n",
    "\n",
    "This notebook summarizes the sampling pipeline and visualizes the CSV outputs generated by `analyze_features.py` for `features_head_v3.db`.\n",
    "\n",
    "What you need:\n",
    "- Python 3.9+\n",
    "- `pandas`, `matplotlib`, `seaborn` (install with `pip install pandas matplotlib seaborn` if missing)\n",
    "- CSVs in `analysis_outputs/`: `feature_head_summary.csv`, `feature_history_summary.csv`, `feature_lifetimes.csv`, `category_summary.csv`\n",
    "- Optional: raw tables in `features_head_v3.db` for deeper joins.\n",
    "\n",
    "Sampling background (v3):\n",
    "- Two-layer sampling from crates.io dump:\n",
    "  - **Core stratum**: top N by reverse dependencies (N=300) + optional core list.\n",
    "  - **Non-core stratum**: filter by downloads >=100 and latest year >=2015, then stratify by (top_category, popularity_band) using p50/p90 downloads.\n",
    "- Only GitHub repos are kept; duplicate owner/repo collapsed (pick higher revdeps/downloads).\n",
    "- Target size: 1500 repos; final unique GitHub repos: 1500.\n",
    "\n",
    "This notebook first re-summarizes sampling outputs (ratios by core/non-core, categories), then visualizes nightly feature usage."
   ]
  },
  {
  "cell_type": "code",
  "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import sqlite3\n",
    "from datetime import datetime\n",
    "\n",
    "# Optional: load sampled CSV to recompute sampling stats\n",
    "SAMPLE_CSV = Path(\"sampled_crates_v3.csv\")\n",
    "DB_PATH = Path(\"features_head_v3.db\")\n",
    "\n",
    "sns.set_theme(style=\"whitegrid\")\n",
    "BASE = Path(\"analysis_outputs\")\n",
    "\n",
    "head_df = pd.read_csv(BASE / \"feature_head_summary.csv\")\n",
    "hist_df = pd.read_csv(BASE / \"feature_history_summary.csv\")\n",
    "life_df = pd.read_csv(BASE / \"feature_lifetimes.csv\")\n",
    "cat_df = pd.read_csv(BASE / \"category_summary.csv\")\n",
    "\n",
    "sample_df = None\n",
    "if SAMPLE_CSV.exists():\n",
    "    sample_df = pd.read_csv(SAMPLE_CSV)\n",
    "\n",
    "conn = None\n",
    "if DB_PATH.exists():\n",
    "    conn = sqlite3.connect(DB_PATH)\n",
    "\n",
    "\n",
    "head_df.head(), hist_df.head(), life_df.head(), cat_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Sampling recap\n",
    "- Core vs non-core composition\n",
    "- Top categories by sample size\n",
    "- HEAD vs EVER nightly ratios for core/non-core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_df is not None:\n",
    "    # Basic counts\n",
    "    total = len(sample_df)\n",
    "    core = sample_df[sample_df[\"is_core\"] == 1]\n",
    "    noncore = sample_df[sample_df[\"is_core\"] == 0]\n",
    "    print(f\"Sample size: {total} (core={len(core)}, non-core={len(noncore)})\")\n",
    "\n",
    "    # Category sizes\n",
    "    top_cats = sample_df[\"top_category\"].value_counts().head(15).reset_index()\n",
    "    top_cats.columns = [\"top_category\", \"count\"]\n",
    "\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    sns.barplot(data=top_cats, x=\"count\", y=\"top_category\", ax=axes[0], palette=\"viridis\")\n",
    "    axes[0].set_title(\"Top categories in sample\")\n",
    "\n",
    "    # Core vs non-core ratio of HEAD/EVER nightly (join with cat_df ratios is coarse; here use cat_df aggregated)\n",
    "    cat_df_sorted = cat_df.sort_values(\"total_repos\", ascending=False).head(15)\n",
    "    sns.barplot(data=cat_df_sorted, x=\"head_nightly_ratio\", y=\"category\", ax=axes[1], palette=\"rocket\")\n",
    "    axes[1].set_title(\"HEAD nightly ratio by category (top 15)\")\n",
    "    axes[1].set_xlim(0, 1)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"sampled_crates_v3.csv not found; skip sampling recap.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Feature usage overview\n",
    "- Distribution of HEAD vs EVER usage counts per feature\n",
    "- Identify dominant gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_df[\"avg_lifetime_days\"] = pd.to_numeric(life_df[\"avg_lifetime_days\"], errors=\"coerce\")\n",
    "life_df[\"median_lifetime_days\"] = pd.to_numeric(life_df[\"median_lifetime_days\"], errors=\"coerce\")\n",
    "life_df[\"num_repos\"] = pd.to_numeric(life_df[\"num_repos\"], errors=\"coerce\")\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "sns.histplot(life_df[\"median_lifetime_days\"].dropna(), bins=40, ax=axes[0], color=\"steelblue\")\n",
    "axes[0].set_title(\"Distribution of feature median lifetimes (days)\")\n",
    "\n",
    "top_long = life_df.dropna(subset=[\"avg_lifetime_days\"]).nlargest(15, \"avg_lifetime_days\")\n",
    "sns.barplot(data=top_long, x=\"avg_lifetime_days\", y=\"feature_name\", ax=axes[1], palette=\"magma\")\n",
    "axes[1].set_title(\"Longest average lifetimes\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4) Retention vs adoption\n",
    "- Still-present ratio = num_still_present / num_repos\n",
    "- Compare with coverage to spot \"sticky\" gates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "life_df[\"still_ratio\"] = life_df[\"num_still_present\"] / life_df[\"num_repos\"]\n",
    "top_ratio = life_df[life_df[\"num_repos\"] >= 5].nlargest(20, \"still_ratio\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.barplot(data=top_ratio, x=\"still_ratio\", y=\"feature_name\", palette=\"crest\")\n",
    "plt.title(\"Top 20 features by still-present ratio (>=5 repos)\")\n",
    "plt.xlim(0, 1.05)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5) Category perspective\n",
    "- Compare per-category nightly reliance on HEAD vs EVER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_df[\"head_nightly_ratio\"] = pd.to_numeric(cat_df[\"head_nightly_ratio\"], errors=\"coerce\")\n",
    "cat_df[\"ever_nightly_ratio\"] = pd.to_numeric(cat_df[\"ever_nightly_ratio\"], errors=\"coerce\")\n",
    "cat_top = cat_df.sort_values(\"total_repos\", ascending=False).head(20)\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 8))\n",
    "sns.barplot(data=cat_top, x=\"head_nightly_ratio\", y=\"category\", ax=axes[0], palette=\"rocket\")\n",
    "axes[0].set_title(\"HEAD nightly ratio by category (top 20 categories)\")\n",
    "sns.barplot(data=cat_top, x=\"ever_nightly_ratio\", y=\"category\", ax=axes[1], palette=\"mako\")\n",
    "axes[1].set_title(\"EVER nightly ratio by category (top 20 categories)\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Next steps (fill in as you iterate)\n",
    "- Join with a feature→stable_date table to plot adoption curves vs stabilization.\n",
    "- Compute time-to-stable intervals: (first substantial adoption) → (stable date).\n",
    "- Segment by core/non-core, popularity bands, downloads/revdeps quantiles.\n",
    "- Highlight currently unstable gates with high still-present ratios and long lifetimes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7) Stable timeline for selected gates\n",
    "Hard-code known stable dates (approx; use release notes/unstable book). Dates as ISO-8601; missing → still unstable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Known stabilization dates (rough, keep in sync with Rust release notes)\n",
    "stable_map = {\n",
    "    \"doc_cfg\": \"1.54.0|2021-07-29\",\n",
    "    \"doc_auto_cfg\": \"1.75.0|2024-01-18\",\n",
    "    \"never_type\": \"1.41.0|2020-01-30\",\n",
    "    \"allocator_api\": None,   # still unstable\n",
    "    \"specialization\": None,  # still unstable\n",
    "    \"plugin\": \"1.29.0|2018-07-19\",  # removed/retired, was unstable\n",
    "    \"test\": \"1.0.0|2015-05-15\",   # public via libtest but feature gate retired\n",
    "}\n",
    "\n",
    "def parse_stable_date(s):\n",
    "    if not s:\n",
    "        return None\n",
    "    if \"|\" in s:\n",
    "        _, date = s.split(\"|\", 1)\n",
    "    else:\n",
    "        date = s\n",
    "    try:\n",
    "        return datetime.fromisoformat(date)\n",
    "    except Exception:\n",
    "        return None\n",
    "\n",
    "stable_dates = {k: parse_stable_date(v) for k, v in stable_map.items()}\n",
    "stable_dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8) Adoption curves for selected gates\n",
    "- Pull from `repo_feature_history` in DB.\n",
    "- Count active repos per quarter (first_seen_date bucket) to see adoption over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def load_history(conn, features):\n", 
    "    qmarks = \",\".join([\"?\"]*len(features))\n",
    "    df = pd.read_sql_query(\n",
    "        f\"\"\"\n",
    "        SELECT feature_name, first_seen_date, last_seen_date, still_present, key\n",
    "        FROM repo_feature_history\n",
    "        WHERE feature_name IN ({qmarks})\n",
    "        \"\"\",\n",
    "        conn,\n",
    "        params=features,\n",
    "    )\n",
    "    df[\"first_seen_date\"] = pd.to_datetime(df[\"first_seen_date\"], errors=\"coerce\")\n",
    "    df[\"last_seen_date\"] = pd.to_datetime(df[\"last_seen_date\"], errors=\"coerce\")\n",
    "    return df\n",
    "\n",
    "selected = [\"doc_cfg\", \"doc_auto_cfg\", \"specialization\", \"allocator_api\", \"never_type\", \"plugin\"]\n",
    "\n",
    "if conn is not None:\n",
    "    hist_sel = load_history(conn, selected)\n",
    "    if not hist_sel.empty:\n",
    "        hist_sel[\"first_quarter\"] = hist_sel[\"first_seen_date\"].dt.to_period(\"Q\")\n",
    "        adoption = (hist_sel.groupby([\"feature_name\", \"first_quarter\"])  # count repos first adopting per quarter\n",
    "                             .size()\n",
    "                             .reset_index(name=\"count\"))\n",
    "        adoption = adoption.sort_values(\"first_quarter\")\n",
    "        all_quarters = adoption[\"first_quarter\"].dropna().sort_values().unique()\n",
    "        plt.figure(figsize=(12,6))\n",
    "        for feat in selected:\n",
    "            sub = adoption[adoption[\"feature_name\"] == feat]\n",
    "            if sub.empty:\n",
    "                continue\n",
    "            # cumulative adoption over time\n",
    "            sub = sub.sort_values(\"first_quarter\")\n",
    "            sub[\"cum\"] = sub[\"count\"].cumsum()\n",
    "            x = sub[\"first_quarter\"].dt.to_timestamp()\n",
    "            plt.plot(x, sub[\"cum\"], marker=\"o\", label=feat)\n",
    "        if len(all_quarters) > 0:\n",
    "            xticks = pd.PeriodIndex(all_quarters).to_timestamp()\n",
    "            plt.gca().set_xticks(xticks)\n",
    "            plt.gca().set_xticklabels([str(q) for q in all_quarters], rotation=75)\n",
    "        plt.title(\"Cumulative adoption over time (selected features)\")\n",
    "        plt.ylabel(\"Repos (cumulative)\")\n",
    "        plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    else:\n",
    "        print(\"No history rows for selected features.\")\n",
    "else:\n",
    "    print(\"DB not available; skip adoption curves.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9) Time-to-stable vs adoption threshold\n",
    "- For stable gates: pick threshold (e.g., first quarter when cumulative >= 5/20 repos)\n",
    "- Compute days from that threshold to stable date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def threshold_date(adoption_df, feat, threshold):\n",
    "    sub = adoption_df[adoption_df[\"feature_name\"] == feat].sort_values(\"first_quarter\")\n",
    "    if sub.empty:\n",
    "        return None\n",
    "    sub = sub.copy()\n",
    "    sub[\"cum\"] = sub[\"count\"].cumsum()\n",
    "    hit = sub[sub[\"cum\"] >= threshold]\n",
    "    if hit.empty:\n",
    "        return None\n",
    "    q = hit.iloc[0][\"first_quarter\"]\n",
    "    # approximate to quarter start\n",
    "    return q.to_timestamp()\n",
    "\n",
    "if conn is not None and 'hist_sel' in locals() and not hist_sel.empty:\n",
    "    thresholds = [5, 20]\n",
    "    results = []\n",
    "    adoption = (hist_sel.groupby([\"feature_name\", \"first_quarter\"]).size().reset_index(name=\"count\"))\n",
    "    for feat in selected:\n",
    "        stab = stable_dates.get(feat)\n",
    "        for th in thresholds:\n",
    "            tdate = threshold_date(adoption, feat, th)\n",
    "            delta_days = None\n",
    "            if tdate is not None and stab is not None:\n",
    "                delta_days = (stab - tdate).days\n",
    "            results.append({\"feature\": feat, \"threshold\": th, \"threshold_date\": tdate, \"stable_date\": stab, \"days_to_stable\": delta_days})\n",
    "    res_df = pd.DataFrame(results)\n",
    "    display(res_df)\n",
    "else:\n",
    "    print(\"Skip time-to-stable; missing data.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10) Core vs non-core, categories, and size signals\n",
    "- Join `repos` with history to see where adoption comes from.\n",
    "- Compare adoption counts by core/non-core and top_category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_repos(conn):\n",
    "    r = pd.read_sql_query(\"SELECT key, is_core, top_categories, downloads_sum, revdeps_sum FROM repos\", conn)\n",
    "    r[\"is_core\"] = r[\"is_core\"].fillna(0).astype(int)\n",
    "    return r\n",
    "\n",
    "if conn is not None:\n",
    "    repos_df = load_repos(conn)\n",
    "    hist_sel = load_history(conn, selected)\n",
    "    if not hist_sel.empty:\n",
    "        merged = hist_sel.merge(repos_df, on=\"key\", how=\"left\")\n",
    "        merged[\"top_cat_primary\"] = merged[\"top_categories\"].fillna(\"\").apply(lambda s: s.split(\",\")[0] if s else \"uncategorized\")\n",
    "        # core vs non-core counts per feature\n",
    "        core_counts = merged.groupby([\"feature_name\", \"is_core\"]).size().reset_index(name=\"count\")\n",
    "        plt.figure(figsize=(10,6))\n",
    "        sns.barplot(data=core_counts, x=\"feature_name\", y=\"count\", hue=\"is_core\", palette=\"Set2\")\n",
    "        plt.title(\"Adoption counts by core/non-core (selected features)\")\n",
    "        plt.xticks(rotation=45)\n",
    "        plt.show()\n",
    "\n",
    "        # category view (top 8 per feature)\n",
    "        for feat in selected:\n",
    "            sub = merged[merged[\"feature_name\"] == feat]\n",
    "            top_cat = sub[\"top_cat_primary\"].value_counts().head(8).reset_index()\n",
    "            top_cat.columns = [\"top_category\", \"count\"]\n",
    "            plt.figure(figsize=(8,4))\n",
    "            sns.barplot(data=top_cat, x=\"count\", y=\"top_category\", palette=\"Blues_r\")\n",
    "            plt.title(f\"Top categories for {feat}\")\n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    else:\n",
    "        print(\"No history data for selected features.\")\n",
    "else:\n",
    "    print(\"DB not available; skip core/category analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11) Pressure indicators for unstable gates\n",
    "- For unstable gates (no stable date): look at adoption level, growth, and retention.\n",
    "- Use current `still_present` counts and cumulative adoption."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if conn is not None and not hist_df.empty:\n",
    "    unstable = [f for f, d in stable_dates.items() if d is None]\n",
    "    pressure = hist_df[hist_df[\"feature_name\"].isin(unstable)].copy()\n",
    "    pressure = pressure.rename(columns={\"ever_repo_count\": \"adoption\"})\n",
    "    # add still_present from lifetimes if available\n",
    "    life_sub = life_df.set_index(\"feature_name\")[\"num_still_present\"]\n",
    "    pressure[\"still_present\"] = pressure[\"feature_name\"].map(life_sub)\n",
    "    display(pressure.sort_values(\"adoption\", ascending=False))\n",
    "else:\n",
    "    print(\"Skip pressure analysis; missing data.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
